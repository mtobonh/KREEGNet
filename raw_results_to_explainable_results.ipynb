{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["OwZpMs44DDRc","9VPRaeAlDEQL","bN49r606DKkc","p1OPd860DurO","Ak8RL_PJ5erb","yba1KA-fe0OY","UZ3_7Qqde5MB"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Download Packages"],"metadata":{"id":"OwZpMs44DDRc"}},{"cell_type":"code","source":["%%capture\n","!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n","!pip install mne #The MNE Package is installed\n","FILEID = \"1-bPsREsUCOiJHzIqi8DQrfSjTAf5VAW_\"\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n","!unzip MI_EEG_ClassMeth.zip #Package with useful functions for motor imagery classification based in EEG.\n","!dir"],"metadata":{"id":"S5IJE1Hm_ZpU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Custom Models"],"metadata":{"id":"9VPRaeAlDEQL"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def generate_upper_triangular_mask(X):\n","  \"\"\"\n","  Generate a boolean mask to extract the upper triangular part of a matrix.\n","  \"\"\"\n","  ones = tf.ones_like(X)\n","  mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s\n","  mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s\n","  mask = tf.cast(mask_a - mask_b, dtype = tf.bool) #Make a bool mask\n","  return mask\n","\n","\n","from tensorflow.keras.layers import Layer\n","import tensorflow as tf\n","import tensorflow_probability as tfp\n","\n","class GFC(Layer):\n","  def __init__(self, **kwargs):\n","    super().__init__(**kwargs)\n","\n","  def build(self, batch_input_shape):\n","    self.gammad = self.add_weight(name = 'gammad',\n","                            shape = (),\n","                            initializer = 'zeros',\n","                            trainable = True)\n","    super().build(batch_input_shape)\n","\n","  def call(self, X):\n","    X = tf.transpose(X, perm  = (0, 3, 1, 2)) #(N, F, C, T)\n","    R = tf.reduce_sum(tf.math.multiply(X, X), axis = -1, keepdims = True) #(N, F, C, 1)\n","    D  = R - 2*tf.matmul(X, X, transpose_b = (0, 1, 3, 2)) + tf.transpose(R, perm = (0, 1, 3, 2)) #(N, F, C, C)\n","\n","    mask = generate_upper_triangular_mask(D[0,0,...]) #(C, C)\n","    triu = tf.expand_dims(tf.boolean_mask(D, mask, axis = 2), axis = -1) #(N, F, C*(C-1)/2, 1)\n","    sigma = tfp.stats.percentile(tf.math.sqrt(triu), 50, axis = 2, keepdims = True) #(N, F, 1, 1)\n","\n","    A = tf.math.exp(-1/(2*tf.pow(10., self.gammad)*tf.math.square(sigma))*D) #(N, F, C, C)\n","    A.set_shape(D.shape)\n","    return A\n","\n","  def compute_output_shape(self, batch_input_shape):\n","    N, C, T, F = batch_input_shape.as_list()\n","    return tf.TensorShape([N, F, C, C])\n","\n","  def get_config(self):\n","    base_config = super().get_config()\n","    return {**base_config}\n","\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, DepthwiseConv2D, Activation, AveragePooling2D, Dropout, SpatialDropout2D, SeparableConv2D, Flatten, Dense\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras.models import Model\n","\n","def FC_EEGNet(number_of_classes: int,\n","          Chans: int,\n","          Samples: int,\n","          dropout_rate: float,\n","          kernLength: int,\n","          F1: int,\n","          D: int,\n","          F2: int,\n","          norm_rate: int,\n","          dropout_type: str) -> Model:\n","    \"\"\" Keras Implementation of EEGNet\n","    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n","    Note that this implements the newest version of EEGNet and NOT the earlier\n","    version (version v1 and v2 on arxiv). We strongly recommend using this\n","    architecture as it performs much better and has nicer properties than\n","    our earlier version. For example:\n","\n","        1. Depthwise Convolutions to learn spatial filters within a\n","        temporal convolution. The use of the depth_multiplier option maps\n","        exactly to the number of spatial filters learned within a temporal\n","        filter. This matches the setup of algorithms like FBCSP which learn\n","        spatial filters within each filter in a filter-bank. This also limits\n","        the number of free parameters to fit when compared to a fully-connected\n","        convolution.\n","\n","        2. Separable Convolutions to learn how to optimally combine spatial\n","        filters across temporal bands. Separable Convolutions are Depthwise\n","        Convolutions followed by (1x1) Pointwise Convolutions.\n","\n","\n","    While the original paper used Dropout, we found that SpatialDropout2D\n","    sometimes produced slightly better results for classification of ERP\n","    signals. However, SpatialDropout2D significantly reduced performance\n","    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n","    the default Dropout in most cases.\n","\n","    Assumes the input signal is sampled at 128Hz. If you want to use this model\n","    for any other sampling rate you will need to modify the lengths of temporal\n","    kernels and average pooling size in blocks 1 and 2 as needed (double the\n","    kernel lengths for double the sampling rate, etc). Note that we haven't\n","    tested the model performance with this rule so this may not work well.\n","\n","    The model with default parameters gives the EEGNet-8,2 model as discussed\n","    in the paper. This model should do pretty well in general, although it is\n","\tadvised to do some model searching to get optimal performance on your\n","\tparticular dataset.\n","    We set F2 = F1 * D (number of input filters = number of output filters) for\n","    the SeparableConv2D layer. We haven't extensively tested other values of this\n","    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n","    overcomplete). We believe the main parameters to focus on are F1 and D.\n","    Inputs:\n","\n","      nb_classes      : int, number of classes to classify\n","      Chans, Samples  : number of channels and time points in the EEG data\n","      dropout_rate     : dropout fraction\n","      kernLength      : length of temporal convolution in first layer. We found\n","                        that setting this to be half the sampling rate worked\n","                        well in practice. For the SMR dataset in particular\n","                        since the data was high-passed at 4Hz we used a kernel\n","                        length of 32.\n","      F1, F2          : number of temporal filters (F1) and number of pointwise\n","                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D.\n","      D               : number of spatial filters to learn within each temporal\n","                        convolution. Default: D = 2\n","      dropout_type     : Either SpatialDropout2D or Dropout, passed as a string.\n","    \"\"\"\n","\n","    if dropout_type == 'SpatialDropout2D':\n","        dropout_type = SpatialDropout2D\n","    elif dropout_type == 'Dropout':\n","        dropout_type = Dropout\n","    else:\n","        raise ValueError('dropout_type must be one of SpatialDropout2D '\n","                         'or Dropout, passed as a string.')\n","\n","    input_   = Input(shape = (Chans, Samples, 1))\n","\n","    ##################################################################\n","    #Temporal Convolution\n","    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n","                          name = 'Temporal_Conv2D',\n","                          use_bias = False)(input_)\n","    block1       = BatchNormalization()(block1)\n","    adj_mat      = GFC(name = 'gfc')(block1)\n","\n","    ##################################################################\n","    #Spatial Convolution\n","    block1       = DepthwiseConv2D((Chans, 1),\n","                                   name = 'Spatial_Depth_wise_Conv2D',\n","                                   depth_multiplier = D,\n","                                   use_bias = False,\n","                                   depthwise_constraint = max_norm(1.))(block1)\n","    block1       = BatchNormalization()(block1)\n","    block1       = Activation('elu')(block1)\n","    block1       = AveragePooling2D((1, 4))(block1)\n","    block1       = dropout_type(dropout_rate)(block1)\n","\n","    ##################################################################\n","    #Separable Convolution\n","    block2       = SeparableConv2D(F2, (1, 16), padding = 'same',\n","                                   name = 'Separable_Conv2D',\n","                                   use_bias = False)(block1)\n","    block2       = BatchNormalization()(block2)\n","    block2       = Activation('elu')(block2)\n","    block2       = AveragePooling2D((1, 8))(block2)\n","    block2       = dropout_type(dropout_rate)(block2)\n","\n","    ##################################################################\n","    # Classification block\n","    flatten      = Flatten(name = 'flatten')(block2)\n","    dense        = Dense(number_of_classes, name = 'output',\n","                         kernel_constraint = max_norm(norm_rate))(flatten)\n","    softmax      = Activation('softmax', name = 'out_activation')(dense)\n","\n","    return Model(inputs=input_, outputs = [softmax, adj_mat])"],"metadata":{"id":"ZHAXu4L5C_nu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"bN49r606DKkc"}},{"cell_type":"code","source":["from gcpds.databases.BCI_Competition_IV import Dataset_2a\n","from typing import Sequence, Tuple\n","from MI_EEG_ClassMeth.FeatExtraction import TimeFrequencyRpr\n","import numpy as np\n","from scipy.signal import resample\n","\n","def load_BCICIV2a(db: Dataset_2a,\n","               sbj: int,\n","               mode: str,\n","               fs: float,\n","               f_bank: np.ndarray,\n","               vwt: np.ndarray,\n","               new_fs: float) -> np.ndarray:\n","\n","  tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n","\n","  db.load_subject(sbj, mode = mode)\n","  X, y = db.get_data() #Load all classes, all channels {EEG, EOG}, reject bad trials\n","  X = X[:,:-3,:] # pick EEG channels\n","  X = X*1e6 #uV\n","  X = np.squeeze(tf_repr.transform(X))\n","  #Resampling\n","  if new_fs == fs:\n","    print('No resampling, since new sampling rate same.')\n","  else:\n","    print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n","    X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n","\n","  return X, y\n","\n","\n","from gcpds.databases import GIGA_MI_ME\n","\n","def load_GIGA_MI_ME(db: GIGA_MI_ME,\n","              sbj: int,\n","              eeg_ch_names: Sequence[str],\n","              fs: float,\n","              f_bank: np.ndarray,\n","              vwt: np.ndarray,\n","              new_fs: float) -> Tuple[np.ndarray, np.ndarray]:\n","\n","  index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n","\n","  tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n","\n","  db.load_subject(sbj)\n","  X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n","  X = X[:, index_eeg_chs, :] #spatial rearrangement\n","  X = np.squeeze(tf_repr.transform(X))\n","  #Resampling\n","  if new_fs == fs:\n","    print('No resampling, since new sampling rate same.')\n","  else:\n","    print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n","    X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n","\n","  return X, y\n","\n","\n","def load_DB(db_name, **load_args):\n","  if db_name == 'BCICIV2a':\n","    X_train, y_train = load_BCICIV2a(**load_args, mode = 'training')\n","    X_test, y_test = load_BCICIV2a(**load_args, mode = 'evaluation')\n","\n","    X_train = np.concatenate([X_train, X_test], axis = 0)\n","    y_train = np.concatenate([y_train, y_test], axis = 0)\n","\n","  elif db_name == 'GIGA_MI_ME':\n","    X_train, y_train = load_GIGA_MI_ME(**load_args)\n","\n","  else:\n","    raise ValueError('No valid database name')\n","\n","  return X_train, y_train\n","\n","from scipy.stats import ks_2samp\n","from scipy.spatial.distance import squareform\n","\n","def KS_matrix(A: np.ndarray, y: np.ndarray) -> np.ndarray:\n","  \"\"\"\n","  Input\n","  -----\n","  A Tensor (batch_dim, n_frquency_bands, n_chans, n_chans)\n","  Output\n","  ------\n","  Q Tensor(n_frquency_bands, n_chans, n_chans)\n","  \"\"\"\n","  _, F, C, _ = A.shape\n","  utri_ind =  np.triu_indices(C, 1)\n","  A = A[:, :, utri_ind[0], utri_ind[1]] #Flatten\n","  D = A.shape[-1]\n","  A_l = A[y == 0]\n","  A_r = A[y == 1]\n","  Q = np.zeros((F, C, C))\n","\n","  for f in range(F):\n","    Q_ = np.zeros(D)\n","    for d in range(D):\n","      Q_[d], _ = ks_2samp(A_l[:, f, d], A_r[:, f, d], alternative = 'two-side', mode = 'auto')\n","    Q[f] = squareform(Q_)\n","\n","  return Q\n","\n","def all_argmmax(x):\n","    if x.shape[0] == 0:\n","        return []\n","    all_ = [0]\n","    max_ = x[0]\n","    for i in range(1, x.shape[0]):\n","        if x[i] > max_:\n","            all_ = [i]\n","            max_ = x[i]\n","        elif x[i] == max_:\n","            all_.append(i)\n","    return all_\n","\n","def relevant_frequencies(A, trh):\n","  rel_freq = []\n","\n","  utri_ind =  np.triu_indices(A.shape[-1], 1)\n","  A = A[:, utri_ind[0], utri_ind[1]] #Flatten\n","  A[A < trh] = 0\n","\n","  for d in range(A.shape[-1]):\n","    if A[:,d].sum() != 0:\n","      rel_freq += all_argmmax(A[:,d])\n","\n","  return rel_freq\n","\n","def renyis_entropy_2(A):\n","  \"\"\"\n","  Renyis entropy with alpha = 2\n","  Input\n","  -----\n","  A Tensor (batch_dim, n_freq_bands, n_chans, n_chans)\n","  Output\n","  ------\n","  H Tensor (batch_dim, n_freq_bands)\n","  \"\"\"\n","  A = A/A.shape[-1]\n","  H = -1*tf.math.log(tf.linalg.trace(tf.linalg.matmul(A ,A)))\n","  H = H.numpy()\n","  H = H.flatten()\n","  return H"],"metadata":{"id":"rJrXs8PG9Sdh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import Drive"],"metadata":{"id":"p1OPd860DurO"}},{"cell_type":"code","source":["from google.colab.drive import mount\n","mount(\"/content/drive\", force_remount=True)"],"metadata":{"id":"Ih6P8uc5DyV0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681076216171,"user_tz":300,"elapsed":28656,"user":{"displayName":"Mateo Tobon Henao","userId":"09711457892284675029"}},"outputId":"2303e7bc-250c-4fde-d354-dba798bb49d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#Config"],"metadata":{"id":"F-bGmj--D0W2"}},{"cell_type":"code","source":["db_name = 'BCICIV2a'\n","nb_classes = 4\n","model_params = dict(number_of_classes = nb_classes,\n","              dropout_rate = 0.5,\n","              kernLength = 32,\n","              F1 = 8,\n","              D = 2,\n","              F2 = 16,\n","              norm_rate = 0.25,\n","              dropout_type = 'Dropout')\n","parent_dir = '/content/drive/Shareddrives/GCPDS - Mateo/Mateo/MI_DL_models/' + db_name + '/'"],"metadata":{"id":"3UpGasG_D2ni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","if db_name == 'BCICIV2a':\n","  db = Dataset_2a('/content/drive/Shareddrives/GCPDS-Databases/BCI_Competition_IV/dataset_2a')\n","  fs = db.metadata['sampling_rate']\n","  load_args = dict(db = db,\n","                 fs = fs,\n","                 f_bank = np.asarray([[4., 40.]]),\n","                 vwt = np.asarray([[2.5, 6]]),\n","                 new_fs = 128.)\n","  subjects = np.arange(db.metadata['subjects']) + 1\n","\n","elif db_name == 'GIGA_MI_ME':\n","  db = GIGA_MI_ME('/content/drive/Shareddrives/GCPDS-Databases/GIGA-MI_ME/')\n","  fs = db.metadata['sampling_rate']\n","  eeg_ch_names = ['Fp1','Fpz','Fp2',\n","                'AF7','AF3','AFz','AF4','AF8',\n","                'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n","                'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n","                'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n","                'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n","                'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n","                'PO7','PO3','POz','PO4','PO8',\n","                'O1','Oz','O2',\n","                'Iz']\n","\n","  load_args = dict(db = db,\n","                  eeg_ch_names = eeg_ch_names,\n","                  fs = fs,\n","                  f_bank = np.asarray([[4., 40.]]),\n","                  vwt = np.asarray([[2.5, 5]]),\n","                  new_fs = 128.)\n","  subjects = np.arange(db.metadata['subjects']) + 1\n","  subjects = np.delete(subjects, [28,33])\n","\n","else:\n","  raise ValueError('No valid database name')"],"metadata":{"id":"gh3FZdrhEVOA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"Ak8RL_PJ5erb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZP_9iIKAKcO"},"outputs":[],"source":["from pickle import load as pload\n","from pickle import dump\n","import pandas as pd"]},{"cell_type":"markdown","source":["### RCKA_EEGNet"],"metadata":{"id":"yba1KA-fe0OY"}},{"cell_type":"code","source":["%%time\n","metrics = ['acc', 'std_acc', 'kappa', 'kappa_std', 'auc', 'std_auc']\n","C = len(db.metadata['channels'])\n","if db_name == 'BCICIV2a':\n","  C -= 3 #Remove EOG channels\n","utri_ind =  np.triu_indices(C, 1)\n","\n","\n","results = np.zeros((subjects.shape[0], len(metrics)))\n","lambda_ = np.zeros((subjects.shape[0]))\n","gammad = np.zeros((subjects.shape[0]))\n","H = np.zeros((subjects.shape[0]))\n","rel_freq = []\n","A_sbjs = np.zeros((subjects.shape[0], int(C*(C-1)*0.5)))\n","\n","for idx, sbj in enumerate(subjects):\n","  with open(parent_dir + 'RCKA_EEGNet/raw_results/sbj' + str(sbj) + '.txt', 'rb') as f:\n","    sbj_results = pload(f)\n","\n","  #Classification performance metrics, hyperparameters\n","  best_index = sbj_results['best_index']\n","  results[idx] = sbj_results['mean_acc'][best_index], sbj_results['std_acc'][best_index], sbj_results['mean_kappa'][best_index], sbj_results['std_kappa'][best_index], sbj_results['mean_auc'][best_index], sbj_results['std_auc'][best_index]\n","  lambda_[idx] = sbj_results['params'][best_index]\n","\n","  #Model paramas\n","  load_args['sbj'] = sbj\n","  X_train, y_train = load_DB(db_name, **load_args)\n","  T = X_train.shape[-1]\n","  X_train = X_train[..., np.newaxis]\n","  model = FC_EEGNet(**model_params, Chans = C, Samples = T)\n","  model.load_weights(parent_dir + 'RCKA_EEGNet/models/' + str(sbj_results['params'][best_index]) + '_sbj' + str(sbj) + '.h5')\n","  gfc_layer = model.get_layer('gfc')\n","  gammad[idx] = gfc_layer.get_weights()[0]\n","  A = model.predict(X_train)[-1] #(N, F, C, C)\n","\n","  #Results for model interpretation\n","  A_k = KS_matrix(A, y_train) #(F, C, C)\n","  rel_freq.append(relevant_frequencies(A_k, 0.5))\n","  H[idx] = renyis_entropy_2(np.max(A_k, axis = 0))\n","  A_sbjs[idx] = np.max(A_k[:, utri_ind[0], utri_ind[1]], axis = 0)\n","\n","#Save results\n","np.save(parent_dir + 'RCKA_EEGNet/reg_eegnet', results)\n","np.save(parent_dir + 'RCKA_EEGNet/lambda_', lambda_)\n","np.save(parent_dir + 'RCKA_EEGNet/gammad', gammad)\n","np.save(parent_dir + 'RCKA_EEGNet/H', H)\n","with open(parent_dir + 'RCKA_EEGNet/rel_freq.txt', 'wb') as f:\n","    dump(rel_freq, f)\n","np.save(parent_dir + 'RCKA_EEGNet/A_sbjs', A_sbjs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQRILav9UPjJ","executionInfo":{"status":"ok","timestamp":1681062001354,"user_tz":300,"elapsed":840494,"user":{"displayName":"Mateo Tobon Henao","userId":"09711457892284675029"}},"outputId":"d57ab7f0-2cb6-4cb1-a0f8-ebdee715d33e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Resampling from 250.000000 to 128.000000 Hz.\n","Resampling from 250.000000 to 128.000000 Hz.\n","18/18 [==============================] - 8s 9ms/step\n","Resampling from 250.000000 to 128.000000 Hz.\n","Resampling from 250.000000 to 128.000000 Hz.\n","18/18 [==============================] - 0s 8ms/step\n","Resampling from 250.000000 to 128.000000 Hz.\n","Resampling from 250.000000 to 128.000000 Hz.\n","17/17 [==============================] - 0s 9ms/step\n","Resampling from 250.000000 to 128.000000 Hz.\n","Resampling from 250.000000 to 128.000000 Hz.\n","16/16 [==============================] - 0s 5ms/step\n","Resampling from 250.000000 to 128.000000 Hz.\n","Resampling from 250.000000 to 128.000000 Hz.\n","17/17 [==============================] - 0s 11ms/step\n","Resampling from 250.000000 to 128.000000 Hz.\n","Resampling from 250.000000 to 128.000000 Hz.\n","14/14 [==============================] - 0s 10ms/step\n","Resampling from 250.000000 to 128.000000 Hz.\n","Resampling from 250.000000 to 128.000000 Hz.\n","18/18 [==============================] - 0s 11ms/step\n","Resampling from 250.000000 to 128.000000 Hz.\n","Resampling from 250.000000 to 128.000000 Hz.\n","17/17 [==============================] - 0s 9ms/step\n","Resampling from 250.000000 to 128.000000 Hz.\n","Resampling from 250.000000 to 128.000000 Hz.\n","16/16 [==============================] - 0s 11ms/step\n","CPU times: user 46.5 s, sys: 6.41 s, total: 52.9 s\n","Wall time: 13min 59s\n"]}]},{"cell_type":"markdown","source":["### EGGNet"],"metadata":{"id":"UZ3_7Qqde5MB"}},{"cell_type":"code","source":["%%time\n","results = np.zeros((subjects.shape[0], len(metrics)))\n","\n","for idx, sbj in enumerate(subjects):\n","  with open(parent_dir + 'EEGNet/raw_results/sbj' + str(sbj) + '.txt', 'rb') as f:\n","    sbj_results = pload(f)\n","\n","  #Classification performance metrics, hyperparameters\n","  results[idx] = sbj_results['mean_acc'], sbj_results['std_acc'], sbj_results['mean_kappa'], sbj_results['std_kappa'], sbj_results['mean_auc'], sbj_results['std_auc']\n","\n","np.save(parent_dir + 'EEGNet/raw_eegnet', results)"],"metadata":{"id":"RJZcRSYjchJw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681076293388,"user_tz":300,"elapsed":7591,"user":{"displayName":"Mateo Tobon Henao","userId":"09711457892284675029"}},"outputId":"3a05c767-bed6-496b-d16a-75d2bc9b7574"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 28.1 ms, sys: 3.7 ms, total: 31.8 ms\n","Wall time: 7.29 s\n"]}]}]}